{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üì¶ Importa√ß√£o de Bibliotecas\n",
    "\n",
    "Este bloco realiza a importa√ß√£o das bibliotecas e m√≥dulos necess√°rios para o processamento, an√°lise e visualiza√ß√£o de grafos com dados em formato `.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import gzip\n",
    "import csv\n",
    "import os\n",
    "from networkx.algorithms.community import louvain_communities, girvan_newman\n",
    "from itertools import islice \n",
    "import networkx as nx\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defini√ß√£o de Vari√°veis\n",
    "\n",
    "- **`input_path`**: Caminho do arquivo de entrada compactado `.txt.gz` contendo os dados originais. Este arquivo √© o ponto de partida para a convers√£o.\n",
    "  - **Exemplo**: `../data/twitter_combined.txt.gz`\n",
    "  \n",
    "- **`output_path`**: Caminho para o arquivo `.csv` gerado a partir do arquivo original. Este arquivo armazenar√° as arestas do grafo extra√≠das do arquivo compactado.\n",
    "  - **Exemplo**: `../csv_files/twitter_network.csv`\n",
    "  \n",
    "- **`CSV_FILE`**: Caminho para o arquivo `.csv` **completo**, utilizado nas execu√ß√µes finais do processo. Esse arquivo cont√©m todos os dados extra√≠dos e processados do arquivo original.\n",
    "  \n",
    "- **`CSV_FILE_SAMPLE`**: Caminho para o arquivo `.csv` **reduzido**, utilizado para desenvolvimento r√°pido e testes com amostras do conjunto de dados. Esse arquivo cont√©m apenas uma fra√ß√£o dos dados, facilitando o desenvolvimento e o teste de funcionalidades.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defini√ßao de vari√°veis\n",
    "input_path = \"../data/twitter_combined.txt.gz\"\n",
    "output_path = \"../csv_files/twitter_network.csv\"\n",
    "\n",
    "CSV_FILE = '../csv_files/twitter_network.csv' # Arquivo completo\n",
    "CSV_FILE_SAMPLE = '../csv_files/twitter_network_sample.csv' # Amostra para desenvolvimento r√°pido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defini√ß√£o de Constantes de Execu√ß√£o\n",
    "\n",
    "- **`USE_SAMPLE = True` ou `False`**: Esta constante define se os algoritmos ser√£o executados utilizando uma **amostra** do conjunto de dados ou o **arquivo completo**.\n",
    "  - **`True`**: Executa os algoritmos utilizando apenas uma amostra do conjunto de dados.\n",
    "  - **`False`**: Executa os algoritmos utilizando o conjunto de dados completo.\n",
    "  \n",
    "- **`SAMPLE_SIZE = 1.0` at√© `0.01`**: Define o **tamanho da amostra** a ser gerada, representando uma fra√ß√£o do total de dados.\n",
    "  - **Exemplo**: `SAMPLE_SIZE = 0.1` corresponde a 10% do conjunto original.\n",
    "  - Essa constante √© utilizada para determinar a quantidade de dados a ser extra√≠da quando `USE_SAMPLE` √© configurado como `True`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_SAMPLE = True\n",
    "SAMPLE_SIZE = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convers√£o de Arquivo `.txt.gz` para `.csv`\n",
    "Este trecho do c√≥digo realiza a convers√£o de um arquivo compactado (`.txt.gz`) contendo pares de v√©rtices (arestas de um grafo) em um arquivo `.csv` com cabe√ßalhos apropriados.\n",
    "\n",
    "- **Verifica√ß√£o de Exist√™ncia do Arquivo de Entrada**: O c√≥digo verifica se o arquivo de entrada, especificado pela vari√°vel `input_path`, existe. Se o arquivo n√£o for encontrado, uma mensagem de erro √© exibida, e o programa √© encerrado com o c√≥digo de erro 1.\n",
    "  \n",
    "- **Verifica√ß√£o de Exist√™ncia do Diret√≥rio de Destino**: O c√≥digo tamb√©m verifica se o diret√≥rio de destino, especificado pela vari√°vel `output_path`, existe. Caso contr√°rio, ele cria o diret√≥rio necess√°rio para armazenar o arquivo `.csv` de sa√≠da.\n",
    "\n",
    "- **Abertura dos Arquivos**: O arquivo compactado `.txt.gz` √© aberto no modo texto (`'rt'`), enquanto o arquivo `.csv` √© aberto no modo escrita (`'w'`), permitindo a grava√ß√£o das arestas extra√≠das.\n",
    "\n",
    "- **Escrita do Cabe√ßalho**: O cabe√ßalho `['source', 'target']` √© escrito no arquivo `.csv`. Esses cabe√ßalhos correspondem aos v√©rtices de cada aresta do grafo, sendo que cada par de v√©rtices representar√° uma aresta.\n",
    "\n",
    "- **Processamento das Linhas do Arquivo de Entrada**: Para cada linha no arquivo `.txt.gz`, o c√≥digo realiza os seguintes passos:\n",
    "  - Divide a linha em dois elementos separados por espa√ßo em branco.\n",
    "  - Verifica se a linha cont√©m exatamente dois elementos (representando uma aresta). Se sim, escreve esse par de v√©rtices no arquivo `.csv`.\n",
    "\n",
    "Esse processo √© √∫til para converter dados de grafos armazenados de forma compactada em um formato estruturado e mais facilmente utiliz√°vel, como o `.csv`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not(os.path.exists(input_path)):\n",
    "    print(f\"Arquivo {input_path} n√£o encontrado.\")\n",
    "    exit(1)\n",
    "\n",
    "if not os.path.exists(os.path.dirname(output_path)):\n",
    "    print(f\"Criando diret√≥rio {os.path.dirname(output_path)}\")\n",
    "    os.makedirs(os.path.dirname(output_path))\n",
    "\n",
    "\n",
    "with gzip.open(input_path, 'rt') as infile, open(output_path, 'w', newline='') as outfile:\n",
    "    writer = csv.writer(outfile)\n",
    "    writer.writerow(['source', 'target'])  \n",
    "    for line in infile:\n",
    "        nodes = line.strip().split()\n",
    "        if len(nodes) == 2:\n",
    "            writer.writerow(nodes)\n",
    "\n",
    "print(f\"Arquivo CSV salvo como {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gera√ß√£o e Salvamento de Amostra do Arquivo CSV\n",
    "\n",
    "Este trecho de c√≥digo realiza a gera√ß√£o de uma amostra aleat√≥ria de um arquivo CSV e a salva em um novo arquivo. Abaixo est√£o os detalhes de cada etapa do processo.\n",
    "\n",
    "- **Exibi√ß√£o da Mensagem de In√≠cio**: O c√≥digo come√ßa exibindo uma mensagem que informa que uma amostra do arquivo CSV est√° sendo gerada, especificando o tamanho da amostra com base na constante `SAMPLE_SIZE`.\n",
    "\n",
    "- **Leitura do Arquivo CSV**: O arquivo CSV completo √© lido e carregado em um DataFrame (`df`) utilizando a fun√ß√£o `pd.read_csv()`. O arquivo CSV est√° localizado no caminho especificado pela vari√°vel `output_path`.\n",
    "\n",
    "- **Gera√ß√£o da Amostra Aleat√≥ria**: O c√≥digo utiliza o m√©todo `sample()` do Pandas para extrair uma amostra aleat√≥ria do DataFrame. O par√¢metro `frac=SAMPLE_SIZE` define a fra√ß√£o dos dados a ser extra√≠da, com base no valor de `SAMPLE_SIZE`. O par√¢metro `random_state=1` garante que a amostra seja reprodut√≠vel, ou seja, a mesma amostra ser√° gerada toda vez que o c√≥digo for executado com as mesmas configura√ß√µes.\n",
    "\n",
    "- **Salvamento da Amostra em um Novo Arquivo CSV**: Ap√≥s a gera√ß√£o da amostra, ela √© salva em um novo arquivo CSV, cujo caminho √© especificado pela vari√°vel `CSV_FILE_SAMPLE`. O par√¢metro `index=False` garante que os √≠ndices do DataFrame n√£o sejam inclu√≠dos no arquivo CSV gerado.\n",
    "\n",
    "- **Exibi√ß√£o da Mensagem de Conclus√£o**: Por fim, uma mensagem √© exibida para informar que a amostra foi salva com sucesso no novo arquivo, cujo caminho √© fornecido pela vari√°vel `CSV_FILE_SAMPLE`.\n",
    "\n",
    "Este processo √© √∫til para trabalhar com uma por√ß√£o representativa dos dados, facilitando a an√°lise e o desenvolvimento sem precisar carregar ou processar o conjunto completo de dados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Gerando uma Amostra do arquivo CSV de tamanho {SAMPLE_SIZE}\")\n",
    "#L√™ o arquivo CSV e gera uma amostra\n",
    "df = pd.read_csv(output_path)\n",
    "sample_df = df.sample(frac=SAMPLE_SIZE, random_state=1)  # Amostra aleat√≥ria\n",
    "sample_df.to_csv(CSV_FILE_SAMPLE, index=False)\n",
    "print(f\"Amostra salva como {CSV_FILE_SAMPLE}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Verifica√ß√£o da Exist√™ncia dos Arquivos `.csv`\n",
    "\n",
    "Este trecho de c√≥digo realiza a verifica√ß√£o da exist√™ncia dos arquivos `.csv` (completo e amostra), e define qual ser√° utilizado durante a execu√ß√£o com base na constante `USE_SAMPLE`.\n",
    "\n",
    "- **Sele√ß√£o do Arquivo Base**: O c√≥digo define a vari√°vel `CURRENT_CSV_FILE` com base no valor de `USE_SAMPLE`:\n",
    "  - Se `USE_SAMPLE = True`, o arquivo de amostra (`CSV_FILE_SAMPLE`) ser√° usado.\n",
    "  - Caso contr√°rio, o arquivo completo (`CSV_FILE`) ser√° utilizado.\n",
    "\n",
    "- **Verifica√ß√£o do Arquivo de Amostra**:\n",
    "  - Exibe uma mensagem indicando que est√° verificando a exist√™ncia do arquivo de amostra.\n",
    "  - Informa se o arquivo de amostra existe ou n√£o.\n",
    "  - Se n√£o existir, informa que √© necess√°rio gerar um novo arquivo de amostra, que pode ser Gerado em [Gera√ß√£o de Amostra](#gera√ß√£o-e-salvamento-de-amostra-do-arquivo-csv).\n",
    "\n",
    "- **Verifica√ß√£o do Arquivo Completo**:\n",
    "  - Verifica se o arquivo `.csv` completo existe.\n",
    "  - Exibe uma mensagem indicando o resultado dessa verifica√ß√£o.\n",
    "  - Se o arquivo n√£o existir, informa que √© necess√°rio gerar um novo arquivo completo, que pode ser gerado em [Gera√ß√£o de Arquivo Completo](#-convers√£o-de-arquivo-txtgz-para-csv).\n",
    "\n",
    "- **Valida√ß√£o Final e Controle de Erro**:\n",
    "  - Verifica se o arquivo selecionado (`CURRENT_CSV_FILE`) realmente existe.\n",
    "  - Caso n√£o exista, exibe uma mensagem de erro e encerra a execu√ß√£o com `exit()`.\n",
    "\n",
    "- **Mensagem Final**:\n",
    "  - Exibe qual arquivo ser√° utilizado na execu√ß√£o do restante do c√≥digo, seja o completo ou a amostra.\n",
    "\n",
    "Esse processo garante que o ambiente esteja corretamente configurado, evitando erros causados por arquivos ausentes ou caminhos incorretos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_SAMPLE:\n",
    "    CURRENT_CSV_FILE = CSV_FILE_SAMPLE\n",
    "else:\n",
    "    CURRENT_CSV_FILE = CSV_FILE\n",
    "\n",
    "if os.path.exists(CSV_FILE_SAMPLE):\n",
    "    print(\"O arquivo de amostra existe.\")\n",
    "else:\n",
    "    print(\"O arquivo de amostra n√£o existe. Gere um novo arquivo de amostra.\")\n",
    "\n",
    "if os.path.exists(CSV_FILE):\n",
    "    print(\"O arquivo completo existe.\")\n",
    "else:\n",
    "    print(\"O arquivo completo n√£o existe. Gere um novo arquivo completo.\")\n",
    "\n",
    "\n",
    "if not os.path.exists(CURRENT_CSV_FILE):\n",
    "    print(f\"ERRO: O arquivo {CURRENT_CSV_FILE} n√£o foi encontrado. Verifique o caminho.\")\n",
    "    exit()\n",
    "\n",
    "print(f\"\\n--- Usando o arquivo: {CURRENT_CSV_FILE} ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Coletar Dados e 2. Construir Grafo ---\n",
    "print(\"\\n1. Lendo dados e construindo o grafo...\")\n",
    "# Load dataset (assumindo formato: source, target para cada intera√ß√£o)\n",
    "df = pd.read_csv(CURRENT_CSV_FILE)\n",
    "\n",
    "if 'source' not in df.columns or 'target' not in df.columns:\n",
    "    print(\"ERRO: O CSV deve conter colunas nomeadas 'source' e 'target'.\")\n",
    "    # Se suas colunas tiverem outros nomes, ajuste aqui ou no arquivo:\n",
    "    # Exemplo: se as colunas forem as duas primeiras sem nome\n",
    "    if len(df.columns) >= 2:\n",
    "        print(f\"Assumindo que as duas primeiras colunas s√£o source e target: {df.columns[0]}, {df.columns[1]}\")\n",
    "        df.columns = ['source', 'target'] + list(df.columns[2:])\n",
    "    else:\n",
    "        print(\"N√£o foi poss√≠vel identificar as colunas source e target.\")\n",
    "        exit()\n",
    "\n",
    "\n",
    "g = nx.DiGraph()\n",
    "\n",
    "# Adicionar arestas com peso baseado na frequ√™ncia de intera√ß√£o\n",
    "for _, row in df.iterrows():\n",
    "    u = row['source']\n",
    "    v = row['target']\n",
    "    if g.has_edge(u, v):\n",
    "        g[u][v]['weight'] += 1\n",
    "    else:\n",
    "        g.add_edge(u, v, weight=1)\n",
    "\n",
    "print(f\"Grafo constru√≠do: N√≥s = {g.number_of_nodes()}, Arestas = {g.number_of_edges()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 Algoritmo PageRank: Identificar n√≥s mais influentes\n",
    "print(\"\\n3.1 Calculando PageRank...\")\n",
    "try:\n",
    "    pagerank = nx.pagerank(g, alpha=0.85, weight='weight') # Usar 'weight' pode ser interessante\n",
    "    # pagerank = nx.pagerank(g, alpha=0.85) # Ou sem peso, se preferir\n",
    "    top_n_pagerank = 10\n",
    "    top_pagerank_nodes = sorted(pagerank.items(), key=lambda x: x[1], reverse=True)[:top_n_pagerank]\n",
    "    print(f\"Top {top_n_pagerank} n√≥s mais influentes (PageRank):\")\n",
    "    for i, (node, score) in enumerate(top_pagerank_nodes, 1):\n",
    "        print(f\"{i}. N√≥: {node} - PageRank Score: {score:.6f}\")\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao calcular PageRank: {e}. Pode ser um grafo desconexo ou muito pequeno.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n3.2 Detectando comunidades (Label Propagation)...\")\n",
    "if g.number_of_nodes() > 0:\n",
    "    g_undirected = None\n",
    "    if nx.is_directed(g):\n",
    "        print(\"Aviso: Os algoritmos Louvain e Girvan-Newman em NetworkX esperam grafos n√£o direcionados.\")\n",
    "        print(\"Convertendo o grafo para n√£o direcionado para aplicar os algoritmos.\")\n",
    "        g_undirected = g.to_undirected()\n",
    "    else:\n",
    "        print(\"O grafo j√° √© n√£o direcionado. Usando-o diretamente.\")\n",
    "        g_undirected = g # Ou g.copy() se quiser evitar modifica√ß√µes acidentais no original\n",
    "\n",
    "    # --- 3.3.1 Algoritmo de Louvain ---\n",
    "    print(\"\\n--- 3.3.1 Algoritmo de Louvain ---\")\n",
    "    try:\n",
    "        # O algoritmo de Louvain √© heur√≠stico e pode dar resultados ligeiramente diferentes.\n",
    "        # O par√¢metro 'seed' pode ser usado para reprodutibilidade.\n",
    "        # O par√¢metro 'resolution' ajusta a granularidade das comunidades.\n",
    "        communities_louvain_sets = louvain_communities(g_undirected, seed=42, resolution=1.0)\n",
    "        communities_louvain = [sorted(list(c)) for c in communities_louvain_sets] # Converter para lista de listas e ordenar\n",
    "\n",
    "        print(f\"N√∫mero de comunidades encontradas (Louvain): {len(communities_louvain)}\")\n",
    "        if communities_louvain:\n",
    "            print(\"Tamanhos das 5 maiores comunidades (Louvain):\")\n",
    "            sorted_communities_louvain = sorted(communities_louvain, key=len, reverse=True)\n",
    "            for i, comm in enumerate(sorted_communities_louvain[:5]):\n",
    "                example_members = str(comm[:3]).strip('[]')\n",
    "                print(f\"Comunidade {i+1}: {len(comm)} membros. Ex: {example_members}...\")\n",
    "        else:\n",
    "            print(\"Nenhuma comunidade detectada pelo algoritmo de Louvain.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao detectar comunidades com Louvain: {e}\")\n",
    "        communities_louvain = []\n",
    "\n",
    "    # --- 3.3.2 Algoritmo de Girvan-Newman ---\n",
    "    print(\"\\n--- 3.3.2 Algoritmo de Girvan-Newman ---\")\n",
    "    try:\n",
    "        # Girvan-Newman √© computacionalmente mais intensivo.\n",
    "        # Retorna um iterador de tuplas de frozensets. Cada tupla √© uma parti√ß√£o.\n",
    "        # O iterador produz parti√ß√µes em diferentes n√≠veis de granularidade,\n",
    "        # come√ßando com todos os n√≥s em uma comunidade e dividindo-as.\n",
    "        # Para uma √∫nica parti√ß√£o, geralmente pegamos o primeiro ou um dos primeiros resultados.\n",
    "        # Ou iteramos at√© um n√∫mero desejado de comunidades.\n",
    "\n",
    "        print(\"Executando Girvan-Newman (pode ser lento para grafos grandes)...\")\n",
    "        gn_communities_generator = girvan_newman(g_undirected)\n",
    "\n",
    "        # Op√ß√£o 1: Pegar o primeiro n√≠vel de parti√ß√£o (geralmente o mais grosseiro ap√≥s a primeira divis√£o)\n",
    "        # ou um n√≠vel espec√≠fico. Para demonstra√ß√£o, pegaremos uma parti√ß√£o com um n√∫mero\n",
    "        # razo√°vel de comunidades, se poss√≠vel, ou a primeira.\n",
    "        # Vamos tentar pegar a parti√ß√£o que resulta em um n√∫mero de comunidades entre 2 e N/2 (aproximadamente)\n",
    "        # ou simplesmente um n√∫mero fixo de itera√ß√µes.\n",
    "\n",
    "        # Para este exemplo, vamos pegar a parti√ß√£o ap√≥s algumas itera√ß√µes (ex: 2 itera√ß√µes para ter 3 comunidades, se poss√≠vel)\n",
    "        # Se o grafo for pequeno, pode haver menos itera√ß√µes.\n",
    "        # k_communities_target = 3 # N√∫mero desejado de comunidades (k)\n",
    "        # Descomente a linha abaixo se quiser um n√∫mero espec√≠fico de comunidades (k)\n",
    "        # e comente a linha `limited_gn_iterations = list(islice(gn_communities_generator, k_communities_target -1))`\n",
    "        # communities_gn_at_k = None\n",
    "        # for i, communities_tuple in enumerate(gn_communities_generator):\n",
    "        #     if i == k_communities_target - 2: # Iteramos k-1 vezes para obter k comunidades (0-indexed)\n",
    "        #         communities_gn_at_k = tuple(sorted(list(c)) for c in communities_tuple)\n",
    "        #         break\n",
    "        # if communities_gn_at_k is None: # Se n√£o atingiu k, pega a √∫ltima parti√ß√£o dispon√≠vel\n",
    "        #     print(f\"N√£o foi poss√≠vel obter exatamente {k_communities_target} comunidades. Usando a √∫ltima parti√ß√£o gerada.\")\n",
    "        #     # Precisamos re-executar ou armazenar a √∫ltima\n",
    "        #     gn_communities_generator = girvan_newman(g_undirected) # Re-executa\n",
    "        #     final_communities_tuple = None\n",
    "        #     for comm_tuple in gn_communities_generator:\n",
    "        #         final_communities_tuple = comm_tuple # Pega a √∫ltima\n",
    "        #     if final_communities_tuple:\n",
    "        #       communities_gn_at_k = tuple(sorted(list(c)) for c in final_communities_tuple)\n",
    "\n",
    "        # Abordagem mais simples: pegar o resultado ap√≥s um n√∫mero fixo de \"cortes\"\n",
    "        # Ou a primeira parti√ß√£o n√£o trivial\n",
    "        num_cuts_for_gn = 2 # N√∫mero de \"cortes\" de arestas a serem feitos. Isso resultar√° em num_cuts_for_gn + 1 comunidades, se poss√≠vel.\n",
    "        \n",
    "        # Tentativa de obter um n√∫mero espec√≠fico de comunidades\n",
    "        # Se o grafo for muito pequeno, pode n√£o ser poss√≠vel obter 'num_cuts_for_gn + 1' comunidades distintas.\n",
    "        desired_num_communities_gn = 3 # Por exemplo, tentamos obter 3 comunidades\n",
    "        found_communities_gn = None\n",
    "\n",
    "        for i, comm_level in enumerate(islice(gn_communities_generator, 10)): # Limita a 10 n√≠veis para n√£o demorar demais\n",
    "            current_communities = tuple(sorted(list(c)) for c in comm_level)\n",
    "            if len(current_communities) >= desired_num_communities_gn:\n",
    "                found_communities_gn = current_communities\n",
    "                print(f\"Girvan-Newman: Parti√ß√£o encontrada com {len(found_communities_gn)} comunidades (n√≠vel {i+1}).\")\n",
    "                break\n",
    "            # Guardar o √∫ltimo caso encontremos menos que o desejado\n",
    "            found_communities_gn = current_communities \n",
    "        \n",
    "        if not found_communities_gn: # Se o gerador estiver vazio (grafo muito pequeno, ex: 1 n√≥)\n",
    "            # Pegar a primeira parti√ß√£o (geralmente todos os n√≥s em uma comunidade, ou logo ap√≥s a primeira divis√£o)\n",
    "            # Re-inicializar o gerador se ele foi consumido\n",
    "            gn_communities_generator = girvan_newman(g_undirected)\n",
    "            try:\n",
    "                first_level_communities_gn = next(gn_communities_generator)\n",
    "                # Converter para lista de listas e ordenar\n",
    "                found_communities_gn = [sorted(list(c)) for c in first_level_communities_gn]\n",
    "                print(f\"Girvan-Newman: Usando o primeiro n√≠vel de parti√ß√£o com {len(found_communities_gn)} comunidades.\")\n",
    "            except StopIteration:\n",
    "                print(\"Girvan-Newman: N√£o foi poss√≠vel gerar parti√ß√µes (grafo pode ser muito pequeno ou j√° desconectado).\")\n",
    "                found_communities_gn = []\n",
    "\n",
    "        communities_gn = found_communities_gn\n",
    "\n",
    "        if communities_gn:\n",
    "            print(f\"N√∫mero de comunidades encontradas (Girvan-Newman): {len(communities_gn)}\")\n",
    "            print(\"Tamanhos das 5 maiores comunidades (Girvan-Newman):\")\n",
    "            # communities_gn j√° √© uma tupla de listas ordenadas (ou lista de listas)\n",
    "            sorted_communities_gn = sorted(communities_gn, key=len, reverse=True)\n",
    "            for i, comm in enumerate(sorted_communities_gn[:5]):\n",
    "                example_members = str(comm[:3]).strip('[]') # comm j√° √© uma lista\n",
    "                print(f\"Comunidade {i+1}: {len(comm)} membros. Ex: {example_members}...\")\n",
    "        else:\n",
    "            print(\"Nenhuma comunidade detectada pelo algoritmo de Girvan-Newman com os crit√©rios atuais.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao detectar comunidades com Girvan-Newman: {e}\")\n",
    "        communities_gn = []\n",
    "\n",
    "else:\n",
    "    print(\"Grafo vazio, pulando detec√ß√£o de comunidades.\")\n",
    "    communities_louvain = []\n",
    "    communities_gn = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n3.3 Calculando medidas de centralidade...\")\n",
    "top_n_centrality = 5\n",
    "\n",
    "if g.number_of_nodes() > 0:\n",
    "    # Grau de centralidade (Out-Degree)\n",
    "    raw_out_degrees = {node: val for node, val in g.out_degree(weight='weight')}\n",
    "    top_out_degree = sorted(raw_out_degrees.items(), key=lambda x: x[1], reverse=True)[:top_n_centrality]\n",
    "    print(f\"\\nTop {top_n_centrality} n√≥s por Centralidade de Sa√≠da (Out-Degree):\")\n",
    "    for i, (node, score) in enumerate(top_out_degree, 1):\n",
    "        print(f\"{i}. N√≥: {node} - Out-Degree: {score}\")\n",
    "\n",
    "    # Conex√£o de centralidade (Betweenness Centrality)\n",
    "    print(f\"\\nCalculando Centralidade de Intermedia√ß√£o (Betweenness)... (Pode demorar)\")\n",
    "    try:\n",
    "        betweenness_centrality = nx.betweenness_centrality(g, weight='weight', normalized=True)\n",
    "        top_betweenness = sorted(betweenness_centrality.items(), key=lambda x: x[1], reverse=True)[:top_n_centrality]\n",
    "        print(f\"Top {top_n_centrality} n√≥s por Centralidade de Intermedia√ß√£o:\")\n",
    "        for i, (node, score) in enumerate(top_betweenness, 1):\n",
    "            print(f\"{i}. N√≥: {node} - Betweenness Score: {score:.6f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao calcular Betweenness Centrality: {e}\")\n",
    "\n",
    "    # Proximidade de centralidade (Closeness Centrality)\n",
    "    print(f\"\\nCalculando Centralidade de Proximidade (Closeness)... (Pode demorar)\")\n",
    "    largest_scc = None\n",
    "    if not nx.is_strongly_connected(g):\n",
    "        print(\"O grafo n√£o √© fortemente conectado. Calculando Closeness para o maior componente fortemente conectado.\")\n",
    "        scc_nodes_list = list(nx.strongly_connected_components(g))\n",
    "        if scc_nodes_list: # Verifica se a lista n√£o est√° vazia\n",
    "            largest_scc_nodes = max(scc_nodes_list, key=len, default=None)\n",
    "            if largest_scc_nodes and len(largest_scc_nodes) > 1:\n",
    "                 largest_scc = g.subgraph(largest_scc_nodes)\n",
    "            else:\n",
    "                print(\"N√£o foi poss√≠vel encontrar um componente fortemente conectado adequado para Closeness.\")\n",
    "        else:\n",
    "            print(\"Nenhum componente fortemente conectado encontrado.\")\n",
    "    else:\n",
    "        largest_scc = g\n",
    "\n",
    "    if largest_scc and largest_scc.number_of_nodes() > 1:\n",
    "        try:\n",
    "            closeness_centrality = nx.closeness_centrality(largest_scc)\n",
    "            top_closeness = sorted(closeness_centrality.items(), key=lambda x: x[1], reverse=True)[:top_n_centrality]\n",
    "            print(f\"Top {top_n_centrality} n√≥s por Centralidade de Proximidade (no maior SCC):\")\n",
    "            for i, (node, score) in enumerate(top_closeness, 1):\n",
    "                print(f\"{i}. N√≥: {node} - Closeness Score: {score:.6f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao calcular Closeness Centrality: {e}\")\n",
    "    else:\n",
    "        print(\"N√£o foi poss√≠vel calcular Closeness Centrality (sem componente adequado ou grafo muito pequeno).\")\n",
    "else:\n",
    "    print(\"Grafo vazio, pulando c√°lculo de centralidades.\")\n",
    "print(\"\\n4. Visualiza√ß√£o e Exporta√ß√£o...\")\n",
    "if g.number_of_nodes() > 0 and g.number_of_nodes() < 500:\n",
    "    print(\"Tentando desenhar o grafo com Matplotlib...\")\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    pos = nx.spring_layout(g, k=0.15, iterations=20)\n",
    "\n",
    "    # Colorir n√≥s por comunidade (Label Propagation)\n",
    "    node_colors_lp = ['gray'] * g.number_of_nodes()\n",
    "    if communities_lp: # Usar as comunidades do Label Propagation\n",
    "        node_to_community_id_lp = {}\n",
    "        for i, comm_nodes in enumerate(communities_lp):\n",
    "            for node in comm_nodes:\n",
    "                node_to_community_id_lp[node] = i\n",
    "        \n",
    "        # Criar lista de cores na ordem de g.nodes()\n",
    "        # Usar um colormap diferente para distinguir visualmente\n",
    "        color_map_lp = plt.cm.get_cmap('tab20', len(communities_lp)) # 'tab20' tem mais cores distintas\n",
    "        \n",
    "        # Mapear cores para os n√≥s na ordem correta que NetworkX os desenhar√°.\n",
    "        # A forma mais segura √© iterar sobre g.nodes() para criar a lista de cores.\n",
    "        final_node_colors_lp = []\n",
    "        node_list_for_drawing = list(g.nodes()) # Obter a ordem dos n√≥s como NetworkX pode us√°-los\n",
    "        for node in node_list_for_drawing:\n",
    "            community_id = node_to_community_id_lp.get(node)\n",
    "            if community_id is not None:\n",
    "                final_node_colors_lp.append(color_map_lp(community_id))\n",
    "            else:\n",
    "                final_node_colors_lp.append('lightgray') # Cor para n√≥s sem comunidade atribu√≠da\n",
    "\n",
    "        nx.draw(g, pos, with_labels=False, node_color=final_node_colors_lp, node_size=15, width=0.1, alpha=0.7, arrows=True)\n",
    "    else: # Se n√£o houver comunidades, desenhar sem cores espec√≠ficas de comunidade\n",
    "        nx.draw(g, pos, with_labels=False, node_size=15, width=0.1, alpha=0.7, arrows=True)\n",
    "\n",
    "    plt.title(f\"Visualiza√ß√£o do Grafo Direcionado (N√≥s: {g.number_of_nodes()}, Arestas: {g.number_of_edges()}) - Colorido por Label Propagation\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Grafo muito grande para desenhar com Matplotlib ou vazio. Considere usar Gephi.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gephi_output_file = \"twitter_network_directed.gexf\"\n",
    "# Adicionar atributos de comunidade ao grafo para exporta√ß√£o, se desejar\n",
    "if communities_lp:\n",
    "    for i, comm_nodes in enumerate(communities_lp):\n",
    "        for node in comm_nodes:\n",
    "            if g.has_node(node): # Verificar se o n√≥ ainda existe (pode n√£o ser necess√°rio aqui)\n",
    "                g.nodes[node]['community_label_prop'] = i\n",
    "try:\n",
    "    nx.write_gexf(g, gephi_output_file)\n",
    "    print(f\"\\nGrafo exportado para '{gephi_output_file}' para visualiza√ß√£o no Gephi.\")\n",
    "    print(\"No Gephi, voc√™ poder√° usar o atributo 'community_label_prop' para colorir os n√≥s.\")\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao exportar para Gephi: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. Mostrar resultados plotando graus de distribui√ß√£o ---\n",
    "print(\"\\n5. Plotando distribui√ß√£o de graus...\")\n",
    "if g.number_of_nodes() > 0:\n",
    "    # Out-degree (quem compartilha)\n",
    "    out_degrees = [g.out_degree(n, weight='weight') for n in g.nodes()]\n",
    "    if not out_degrees:\n",
    "        print(\"N√£o foi poss√≠vel obter out-degrees para plotagem.\")\n",
    "    else:\n",
    "        degree_counts_out = Counter(out_degrees)\n",
    "        degrees_out, counts_out = zip(*degree_counts_out.items())\n",
    "\n",
    "    # In-degree (quem √© alvo/referenciado)\n",
    "    in_degrees = [g.in_degree(n, weight='weight') for n in g.nodes()]\n",
    "    if not in_degrees:\n",
    "        print(\"N√£o foi poss√≠vel obter in-degrees para plotagem.\")\n",
    "    else:\n",
    "        degree_counts_in = Counter(in_degrees)\n",
    "        degrees_in, counts_in = zip(*degree_counts_in.items())\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(12, 12))\n",
    "\n",
    "    # Plot Out-Degree Linear\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.bar(degrees_out, counts_out, width=0.80, color='blue')\n",
    "    plt.title(\"Distribui√ß√£o de Out-Degree (Escala Linear)\")\n",
    "    plt.ylabel(\"Contagem\")\n",
    "    plt.xlabel(\"Out-Degree\")\n",
    "\n",
    "    # Plot Out-Degree Log-Log\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.loglog(degrees_out, counts_out, marker='.', linestyle='none', color='blue')\n",
    "    plt.title(\"Distribui√ß√£o de Out-Degree (Escala Log-Log)\")\n",
    "    plt.ylabel(\"Contagem (Log)\")\n",
    "    plt.xlabel(\"Out-Degree (Log)\")\n",
    "\n",
    "    # Plot In-Degree Linear\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.bar(degrees_in, counts_in, width=0.80, color='green')\n",
    "    plt.title(\"Distribui√ß√£o de In-Degree (Escala Linear)\")\n",
    "    plt.ylabel(\"Contagem\")\n",
    "    plt.xlabel(\"In-Degree\")\n",
    "\n",
    "    # Plot In-Degree Log-Log\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.loglog(degrees_in, counts_in, marker='.', linestyle='none', color='green')\n",
    "    plt.title(\"Distribui√ß√£o de In-Degree (Escala Log-Log)\")\n",
    "    plt.ylabel(\"Contagem (Log)\")\n",
    "    plt.xlabel(\"In-Degree (Log)\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Grafo vazio, pulando plotagem de distribui√ß√£o de graus.\")\n",
    "\n",
    "print(\"\\n--- An√°lise Conclu√≠da ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ProjetoTAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
